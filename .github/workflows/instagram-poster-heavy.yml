name: Instagram Heavy Poster (Actual Posting)

on:
  # Only triggered by the smart checker or manually
  workflow_dispatch:
    inputs:
      triggered_by:
        description: 'Triggered by'
        required: false
        default: 'manual'
      check_time:
        description: 'Check timestamp'
        required: false
        default: ''

jobs:
  post-to-instagram:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # Allow up to 3 hours for large video posts to many accounts
    
    steps:
      - name: Log trigger source
        run: |
          echo "üéØ Triggered by: ${{ github.event.inputs.triggered_by || 'manual' }}"
          echo "‚è∞ Check time: ${{ github.event.inputs.check_time || 'now' }}"
          echo "üîë Run ID: ${{ github.run_id }}"
      
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install full dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run Instagram poster
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          FB_ACCESS_TOKEN: ${{ secrets.FB_ACCESS_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_BUCKET_NAME: ${{ secrets.AWS_BUCKET_NAME }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          GITHUB_ACTIONS: "true"
          GITHUB_RUN_ID: ${{ github.run_id }}
        run: |
          python -c "
          import sys
          import os
          from datetime import datetime
          from sqlalchemy import create_engine, text
          from sqlalchemy.pool import NullPool
          
          print('='*60)
          print(f'üöÄ Heavy Poster Started at {datetime.utcnow()} UTC')
          print(f'üîë Run ID: {os.getenv(\"GITHUB_RUN_ID\")}')
          print('='*60)
          
          # Acquire lock at the START of heavy workflow
          db_url = os.getenv('DATABASE_URL')
          if db_url:
              engine = create_engine(db_url, poolclass=NullPool)
              with engine.connect() as conn:
                  run_id = os.getenv('GITHUB_RUN_ID', 'unknown')
                  conn.execute(text(
                      'INSERT INTO workflow_locks (lock_name, locked_at, locked_by) '
                      'VALUES (:name, :time, :run_id) '
                      'ON CONFLICT (lock_name) DO UPDATE SET locked_at = :time, locked_by = :run_id'
                  ), {'name': 'instagram_poster', 'time': datetime.utcnow(), 'run_id': run_id})
                  conn.commit()
                  print(f'üîí Lock acquired by run {run_id}')
          
          try:
              from services.scheduler import run_scheduled_posts
              
              # Run the actual posting
              results = run_scheduled_posts()
              
              if results:
                  print(f'\n‚úÖ Successfully processed {len(results)} posts:')
                  for result in results:
                      print(f'  - {result}')
              else:
                  print('\nüì≠ No posts were due (they may have been processed already)')
              
              print('\n' + '='*60)
              print('‚úÖ Heavy Poster Complete')
              print('='*60)
              
          except Exception as e:
              print(f'\n‚ùå Error in heavy poster: {e}')
              import traceback
              traceback.print_exc()
              sys.exit(1)
              
          finally:
              # Always release lock when workflow completes
              print('\nüîì Releasing workflow lock...')
              try:
                  db_url = os.getenv('DATABASE_URL')
                  if db_url:
                      engine = create_engine(db_url, poolclass=NullPool)
                      with engine.connect() as conn:
                          run_id = os.getenv('GITHUB_RUN_ID', 'unknown')
                          result = conn.execute(text(
                              'DELETE FROM workflow_locks WHERE lock_name = :name AND locked_by = :run_id'
                          ), {'name': 'instagram_poster', 'run_id': run_id})
                          conn.commit()
                          
                          if result.rowcount > 0:
                              print(f'‚úÖ Lock released successfully by run {run_id}')
                          else:
                              print(f'‚ö†Ô∏è No lock found for run {run_id} (may have been released already)')
                  else:
                      print('‚ö†Ô∏è DATABASE_URL not set, cannot release lock')
              except Exception as lock_err:
                  print(f'‚ùå Error releasing lock: {lock_err}')
                  # Don't fail the workflow just because lock release failed
          "
      
      - name: Summary
        if: always()
        run: |
          echo "----------------------------------------"
          echo "üìä Workflow Summary:"
          echo "- Run ID: ${{ github.run_id }}"
          echo "- Triggered by: ${{ github.event.inputs.triggered_by || 'manual' }}"
          echo "- Completed at: $(date)"
          echo "----------------------------------------"